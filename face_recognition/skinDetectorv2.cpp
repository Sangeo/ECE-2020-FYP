/**
This file is used for trying out various types of facial recognition,
as well as skin masking and extraction of skin regions
*/
#include "opencv_helper.h"

using namespace cv;

cv::CascadeClassifier faceCascade;

Mat detectAndDisplay(cv::Mat f);

Rect findPoints(
	std::vector<Rect> faces,
	int bestIndex,
	double scaleFactor);
Mat skinDetection(Mat frameC, Rect originalFaceRect);


std::deque<double> topLeftX;
std::deque<double> topLeftY;
std::deque<double> botRightX;
std::deque<double> botRightY;

static bool DEBUGGING_MODE = true;

int main(int argc, const char** argv) {
	//Introducing the module
	cv::CommandLineParser parser(argc, argv,
		"{help h||}"
		"{face_cascade|data/haarcascades/haarcascade_frontalface_alt.xml|Path to face cascade.}"
		"{camera|0|Camera device number.}");
	parser.about("\nPress Esc to quit program\nThis program demonstrates signal decomposition by color in openCV with facial recognition in a video stream");
	parser.printMessage();
	//-- 1. Load the cascades
	cv::String faceCascadeName = cv::samples::findFile(parser.get<cv::String>("face_cascade"));
	if (!faceCascade.load(faceCascadeName)) {
		std::cout << "--(!)Error loading face cascade\n";
		return -1;
	};

	//-- 2. Read the video stream
	cv::VideoCapture capture(0); //inputs into the Mat frame as CV_8UC3 format (unsigned integer)
	capture.set(cv::CAP_PROP_FPS, 30);
	capture.set(cv::CAP_PROP_FRAME_WIDTH, 1280);
	capture.set(cv::CAP_PROP_FRAME_HEIGHT, 720);
	// check that the camera is open
	if (!capture.isOpened()) {
		std::cout << "--(!)Error opening video capture\n";
		return -1;
	}
	// this frame will store all information about the video captured by the camera
	cv::Mat frame;
	cv::Scalar lower;
	cv::Scalar upper;
	//define lower and upper bounds for skin detection
	//these values will be in HSV format NOT BGR
	int useHSV = 0;
	if (useHSV == 1) {
		//HSV values - Hue, Saturation and Value 
		lower = cv::Scalar(0, 48, 80);
		upper = cv::Scalar(20, 255, 255);
	}
	else {
		// YCrCb values - 
	//The Y' channel (luma) is basically the grayscale version of the original image. 
	// The Cr and Cb channels contain the colour information. They can be highly compressed.
		lower = cv::Scalar(0, 133, 70);
		upper = cv::Scalar(255, 173, 127);
	}


	for (;;) {
		if (capture.read(frame)) {
			detectAndDisplay(frame);
		}

		if (cv::waitKey(1) > 0) {
			break; // if escape is pressed at any time
		}
	}
}

/** Function detectAndDisplay
	Detects a face in a video feed from camera and
	return the frame of information which contains the color information in it.
	Input: current frame (raw)
	Output: current skin (raw);
*/
Mat detectAndDisplay(Mat frame) {

	Mat frameClone = frame.clone();
	Mat procFrame;
	Mat frameGray;
	std::vector<Rect> faces;
	std::vector<int> numDetections;

	//downsizing image before processing
	const double scaleFactor = 1.0 / 7.0;
	resize(frameClone, procFrame, cv::Size(), scaleFactor, scaleFactor);
	//convert the image into a grayscale image which will be equalised for face detection
	cvtColor(procFrame, frameGray, COLOR_BGR2GRAY); // convert the current frame into grayscale
	equalizeHist(frameGray, frameGray); // equalise the grayscale img
	//use the Haar cascade classifier to process the image with training files.
	faceCascade.detectMultiScale(frameGray.clone(), faces, numDetections, 1.1, 3, 0 | CASCADE_SCALE_IMAGE, Size(30, 30));
	// finds the best face possible on the current frame
	int bestIndex = std::distance(
		numDetections.begin(),
		std::max_element(numDetections.begin(), numDetections.end()));

	Rect faceROI;
	Mat trueROI;
	if (!faces.empty()) {
		//find the faceROI using a moving average to ease the noise out	
		faceROI = findPoints(faces, bestIndex, scaleFactor);

		if (!faceROI.empty()) {
			// draws on the current face region of interest
			Point2i tempTL, tempBR;
			tempTL.x = faceROI.tl().x - 40 ;
			if (tempTL.x <= 0) {
				tempTL.x = faceROI.tl().x;
			}
			tempTL.y = faceROI.tl().y - 40;
			if (tempTL.y <= 0) {
				tempTL.y = faceROI.tl().y;
			}
			tempBR.x = faceROI.br().x + 40;
			if (tempBR.x >= frameClone.cols) {
				tempBR.x = faceROI.br().x;
				std::cout << "tempBR.x is over the frame's allowable limit" << std::endl;
			}
			tempBR.y = faceROI.br().y + 40;
			if (tempBR.y >= frameClone.rows) {
				tempBR.y = faceROI.br().y;
				std::cout << "tempBR.y is over the frame's allowable limit" << std::endl;
			}

			Rect tempRect(tempTL, tempBR);

			rectangle(frameClone, tempRect, Scalar(0, 0, 255), 1, LINE_4, 0);

			trueROI = skinDetection(frameClone, tempRect);
		}
	}
	imshow("frame", frameClone);

	return trueROI;
}

/** Function: findPoints
	locates the best face ROI coordinates using a simple
	moving average to eliminate noise generated by the casscade classifier

	uses a window size of 8 frames to ensure coordinates do not jump around

	Input:
	- vector of face locations,
	- the best face obtained,
	- the scale factor used to downsize the original image
	Output:
	- current face ROI coordinates, scaled to original image size
*/
Rect findPoints(std::vector<Rect> faces, int bestIndex, double scaleFactor) {

	double tlX = floor(faces[bestIndex].tl().x * (1 / scaleFactor));
	double tlY = floor(faces[bestIndex].tl().y * (1 / scaleFactor));
	double brX = floor(faces[bestIndex].br().x * (1 / scaleFactor));
	double brY = floor(faces[bestIndex].br().y * (1 / scaleFactor));

	//temporary variables
	double avgtlX;
	double avgtlY;
	double avgbrX;
	double avgbrY;
	double sumTX = 0;
	double sumTY = 0;
	double sumBX = 0;
	double sumBY = 0;
	//if the queue size is above a certain number we start to take the average of the frames
	int frameWindow = 6;
	if (topLeftX.size() >= frameWindow) {

		//Take the sum of all elements in the current frame window
		for (int i = 0; i < frameWindow; i++) {
			sumTX += topLeftX[i];
			sumTY += topLeftY[i];
			sumBX += botRightX[i];
			sumBY += botRightY[i];
		}

		//calculate the running average (flooring the number)
		avgtlX = std::floor(sumTX / frameWindow);
		avgtlY = std::floor(sumTY / frameWindow);
		avgbrX = std::floor(sumBX / frameWindow);
		avgbrY = std::floor(sumBY / frameWindow);

		//pop the front of the queue
		topLeftX.pop_front();
		topLeftY.pop_front();
		botRightX.pop_front();
		botRightY.pop_front();
		//add the current number into the queue
		topLeftX.push_back(tlX);
		topLeftY.push_back(tlY);
		botRightX.push_back(brX);
		botRightY.push_back(brY);

		//cout << avgtlX << "," << avgtlY << "," << avgbrX << "," << avgbrY << endl;
		//set the average as the points used for the face ROI rectangles
		Point avgTopLeft = Point(avgtlX, avgtlY);
		Point avgBotRight = Point(avgbrX, avgbrY);
		Rect faceROI = Rect(avgTopLeft, avgBotRight);

		return faceROI;
	}
	else {
		//add to the queue the current face positions
		topLeftX.push_back(tlX);
		topLeftY.push_back(tlY);
		botRightX.push_back(brX);
		botRightY.push_back(brY);
		Point avgTopLeft = Point(tlX, tlY);
		Point avgBotRight = Point(brX, brY);
		Rect faceROI = Rect(avgTopLeft, avgBotRight);

		return faceROI;
	}

	return Rect();
}


/** Function: skinDetection
	Input: Current frame, face ROI
	Output: Skin information

	Obtains skin in the detected face ROI, two thresholds are applied to the frame
	These following values work best under a bright white lamp
	1. YCrCb values
	lBound = (0, 133, 70);
	uBound = (255, 173, 127);

	2. HSV values
	lBound = (0, 30, 70);
	lBound = (17, 170, 255);
	The obtained skin mask will be applied using a 10,10 kernel which with the use of
	morphologyex (opening), clearing out false positives outside the face

*/

Mat skinDetection(Mat frameC, Rect originalFaceRect) {
	
	Mat frameFace = frameC(originalFaceRect).clone();
	Mat yccFace, hsvFace, imgFilter;
	cv::cvtColor(frameFace, yccFace, COLOR_BGR2YCrCb, CV_8U);
	cv::cvtColor(frameFace, hsvFace, COLOR_BGR2HSV, CV_8U);
	int min_cr, min_cb, max_cr, max_cb;
	min_cr = 133;
	max_cr = 173;
	min_cb = 77;
	max_cb = 127;
	Point2i tempTL, tempBR;
	tempTL.x = 60;
	tempTL.y = 60;
	tempBR.x = frameFace.rows - 100;
	tempBR.y = frameFace.cols - 100;
	Rect tempRect(tempTL, tempBR);
	
	//low-pass spatial filtering to remove high frequency content
	yccFace = yccFace(tempRect).clone();
	//medianBlur(yccFace, yccFace, 5);

	//colour segmentation
	cv::inRange(yccFace, Scalar(0, min_cr, min_cb), Scalar(255, max_cr, max_cb), imgFilter);
	
	//Morphology on the imgFilter to remove noise introduced by colour segmentation
	Mat kernel = Mat::ones(Size(7, 7), CV_8U);
	cv::morphologyEx(imgFilter, imgFilter, MORPH_OPEN, kernel,Point (-1,-1),2);
	

	Mat skin;
	//frameFace.copyTo(skin, imgFilter);
	imshow("SKIN", imgFilter);
	return skin;
}
